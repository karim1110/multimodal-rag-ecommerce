{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b411594b-1de8-4d95-ad22-8e0f589e8a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"chatbot_backend.ipynb\n",
    "\n",
    "Automatically generated by Colab.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1bhEnmZFSyhcjJdn1VhPvUdAwtTOgHGc6\n",
    "\"\"\"\n",
    "\n",
    "# chatbot_backend.py\n",
    "\n",
    "from transformers import (\n",
    "    CLIPProcessor,\n",
    "    CLIPModel,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    pipeline\n",
    ")\n",
    "from PIL import Image\n",
    "import torch\n",
    "import dotenv\n",
    "import requests\n",
    "\n",
    "\n",
    "# ----- Configuration -----\n",
    "PINECONE_API_KEY = dotenv.get_key(\".env\", \"PINECONE_API_KEY\")\n",
    "PERPLEXITY_API_KEY = dotenv.get_key(\".env\", \"PERPLEXITY_API_KEY\")\n",
    "INDEX_NAME = \"multimodal\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Loaded Pinecone key:\", bool(PINECONE_API_KEY))\n",
    "\n",
    "\n",
    "# ----- Pinecone Initialization -----\n",
    "from pinecone import Pinecone\n",
    "\n",
    "print(PINECONE_API_KEY)\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "index = pc.Index(INDEX_NAME)\n",
    "\n",
    "\n",
    "# ----- Load CLIP -----\n",
    "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n",
    "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "\n",
    "def generate_with_perplexity2(prompt):\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {PERPLEXITY_API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": \"llama-3.1-sonar-large-128k-online\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful product assistant. Please answer whether we need to return 'text', 'image' or 'both' for the given query in our rag system. You answer should just be these values only ['text','image','both']\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"\"\" Please answer whether we need to return 'text', 'image' or 'both' for the given query in our rag system. You answer should just be these values only ['text','image','both']\n",
    "                prompt\"\"\"\n",
    "            }\n",
    "        ],\n",
    "        \"temperature\": 0.7,\n",
    "        \"max_tokens\": 256\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(\n",
    "            \"https://api.perplexity.ai/chat/completions\",\n",
    "            json=payload,\n",
    "            headers=headers,\n",
    "            timeout=10\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print(f\"Perplexity API HTTP Error: {e.response.text}\")\n",
    "        return \"Sorry, I couldn't get a response from the AI assistant.\"\n",
    "    except Exception as e:\n",
    "        print(f\"Perplexity API error: {str(e)}\")\n",
    "        return \"Sorry, there was an error processing your request.\"\n",
    "\n",
    "return_flag=generate_with_perplexity2(\"What are the features of the Samsung Galaxy S21?\")\n",
    "\n",
    "\n",
    "\n",
    "# ----- Add Perplexity API function -----\n",
    "def generate_with_perplexity(prompt):\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {PERPLEXITY_API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": \"llama-3.1-sonar-large-128k-online\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful product assistant.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        \"temperature\": 0.7,\n",
    "        \"max_tokens\": 256\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(\n",
    "            \"https://api.perplexity.ai/chat/completions\",\n",
    "            json=payload,\n",
    "            headers=headers,\n",
    "            timeout=10\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print(f\"Perplexity API HTTP Error: {e.response.text}\")\n",
    "        return \"Sorry, I couldn't get a response from the AI assistant.\"\n",
    "    except Exception as e:\n",
    "        print(f\"Perplexity API error: {str(e)}\")\n",
    "        return \"Sorry, there was an error processing your request.\"\n",
    "\n",
    "# ----- Embedding Functions -----\n",
    "def embed_text(text):\n",
    "    inputs = clip_processor(text=[text], return_tensors=\"pt\", padding=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        return clip_model.get_text_features(**inputs)[0].cpu().numpy().tolist()\n",
    "\n",
    "def embed_image(file):\n",
    "    image = Image.open(file).convert(\"RGB\")\n",
    "    inputs = clip_processor(images=image, return_tensors=\"pt\", padding=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        return clip_model.get_image_features(**inputs)[0].cpu().numpy().tolist()\n",
    "\n",
    "# ----- Main Retrieval + Generation Function -----\n",
    "\n",
    "\n",
    "def query_vector_db(text=None, image=None, return_type=\"both\"):\n",
    "    return_type=generate_with_perplexity2(text)\n",
    "    if not text and not image:\n",
    "        return {\n",
    "            \"answer\": \"Please provide a text or image input.\",\n",
    "            \"image_url\": None,\n",
    "            \"retrieved_items\": []\n",
    "        }\n",
    "    return_type=generate_with_perplexity2(text)\n",
    "    if return_type not in ['image','text','both']:\n",
    "        return_type='both'\n",
    "        \n",
    "    # 1. Embed the input(s)\n",
    "    query_vec = None\n",
    "    query_text = \"\"\n",
    "    if text and not image:\n",
    "        query_vec = embed_text(text)\n",
    "        query_text = text\n",
    "    elif image and not text:\n",
    "        query_vec = embed_image(image)\n",
    "        query_text = \"What is this product?\"\n",
    "    elif text and image:\n",
    "        # Combine text and image embeddings (optional: use a weighted average or concatenation)\n",
    "        text_vec = embed_text(text)\n",
    "        image_vec = embed_image(image)\n",
    "        query_vec = [(t + i) / 2 for t, i in zip(text_vec, image_vec)]\n",
    "        query_text = text\n",
    "\n",
    "    # 2. Determine which vector types to return\n",
    "    if return_type == \"both\":\n",
    "        query_types = [\"text\", \"image\"]\n",
    "    elif return_type in {\"text\", \"image\"}:\n",
    "        query_types = [return_type]\n",
    "    else:\n",
    "        raise ValueError(\"return_type must be one of: 'text', 'image', 'both'\")\n",
    "\n",
    "    # 3. Query Pinecone and build product cards\n",
    "    retrieved_info = \"\"\n",
    "    retrieved_items = []\n",
    "\n",
    "    for qtype in query_types:\n",
    "        results = index.query(\n",
    "            vector=query_vec,\n",
    "            top_k=5,\n",
    "            include_metadata=True,\n",
    "            filter={\"type\": {\"$eq\": qtype}}\n",
    "        )\n",
    "\n",
    "        for match in results.get(\"matches\", []):\n",
    "            md = match.get(\"metadata\", {})\n",
    "            name = md.get(\"name\", \"Unknown Product\")\n",
    "            category = md.get(\"category\", \"Unknown\")\n",
    "            price = md.get(\"price\", \"N/A\")\n",
    "            #product_id = md.get(\"product_id\", \"N/A\")\n",
    "            vector_id = match.get(\"id\", \"\")\n",
    "            product_id = vector_id.split(\"_\")[0] if \"_\" in vector_id else \"N/A\"\n",
    "\n",
    "            image_type = md.get(\"type\", \"unknown\")\n",
    "            img_idx = md.get(\"img_idx\", None)\n",
    "\n",
    "            retrieved_info += (\n",
    "                f\"- Name: {name}, Category: {category}, Price: {price}, \"\n",
    "                f\"ID: {product_id}, Type: {image_type}\\n\"\n",
    "            )\n",
    "\n",
    "            retrieved_items.append({\n",
    "                \"product_id\": product_id,\n",
    "                \"title\": name,\n",
    "                \"description\": f\"{category} â€“ ${price}\",\n",
    "                \"image_type\": image_type,\n",
    "                \"img_idx\": img_idx  # Used to fetch the right image from your CSV/URL store\n",
    "            })\n",
    "\n",
    "    # 4. Prompt LLM\n",
    "    prompt = f\"\"\"You are a helpful product assistant.\n",
    "\n",
    "Product Info:\n",
    "{retrieved_info}\n",
    "\n",
    "Question:\n",
    "{query_text}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "    answer = generate_with_perplexity(prompt)\n",
    "\n",
    "    return {\n",
    "        \"answer\": answer,\n",
    "        \"image_url\": None,\n",
    "        \"retrieved_items\": retrieved_items\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "preprocessed_df=pd.read_csv(\"D:\\\\UCHICAGO\\\\UChicago Courses\\\\Generative AI Principles\\\\Final_Project\\\\dataset\\\\preprocessed_data.csv\")\n",
    "product_id_url=queryreturn['retrieved_items'][5]['product_id']\n",
    "image_url=preprocessed_df[preprocessed_df['Uniq Id']==product_id_url]['Image']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
